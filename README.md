# High-Scale Energy Ingestion Engine (HSEIE)

A production-ready backend system for ingesting and analyzing telemetry data from 10,000+ Smart Meters and EV Fleets.

## ğŸ¯ Project Overview

This system handles **28.8 million records per day** from IoT devices sending data every 60 seconds. It provides:

- **Polymorphic Ingestion**: Validates and routes meter and vehicle telemetry streams
- **Hot/Cold Storage Strategy**: Separates current state from historical data for optimal performance
- **Efficient Analytics**: Sub-second queries on billions of records using partition pruning
- **Scalable Architecture**: Built to handle 333 writes/second with room to scale to millions

## ğŸ“Š System Architecture

```
IoT Devices (10K meters + 10K vehicles)
         â†“
    NestJS API (Ingestion Layer)
    - Validation (DTOs)
    - Dual-write strategy
         â†“
    PostgreSQL Database
    â”œâ”€ Hot Tables (UPSERT)
    â”‚  â”œâ”€ meter_current (20K rows)
    â”‚  â””â”€ vehicle_current (20K rows)
    â”‚
    â””â”€ Cold Tables (INSERT, Partitioned)
       â”œâ”€ meter_history (29M rows/day)
       â””â”€ vehicle_history (29M rows/day)
         â†“
    Analytics Engine
    - 24-hour performance summaries
    - Efficiency calculations (DC/AC ratio)
```

## ğŸ”‘ Key Features

### 1. **Hot/Cold Table Separation**

**Hot Tables (Current State)**
- Purpose: Dashboard queries ("What's the current SoC?")
- Operation: UPSERT (update if exists, insert if not)
- Size: Fixed 20K rows
- Query Time: <10ms (O(1) lookup)

**Cold Tables (Historical Audit Trail)**
- Purpose: Analytics and reporting
- Operation: INSERT only (append-only)
- Size: 28.8M rows/day (growing)
- Query Time: <500ms (with partition pruning)

### 2. **Partition Pruning**

Historical tables are partitioned by day:
```sql
vehicle_history_2026_02_08
vehicle_history_2026_02_09  â† Today's partition
vehicle_history_2026_02_10
```

A 24-hour query only scans **2 partitions** instead of the entire table (7 millionÃ— reduction).

### 3. **Data Correlation Strategy**

The system correlates meter (AC) and vehicle (DC) data to calculate power efficiency. Here's how it works:

**Correlation Logic:**
- Each vehicle is associated with a meter (1:1 relationship)
- Vehicle ID matches Meter ID (e.g., `VEHICLE_001` â†” `METER_001`)
- Data is joined within a **Â±30 second window** to handle clock drift

**Why Â±30 seconds?**
- IoT devices may have slight clock synchronization differences
- Network latency can cause timestamp variations
- 30 seconds provides tolerance while maintaining accuracy

**Analytics Query:**
```sql
SELECT 
  SUM(m.kwh_consumed_ac) as total_ac,      -- From meter (grid side)
  SUM(v.kwh_delivered_dc) as total_dc,     -- From vehicle (battery side)
  (total_dc / total_ac) * 100 as efficiency -- Efficiency ratio
FROM vehicle_history v
INNER JOIN meter_history m ON 
  v.vehicle_id = m.meter_id 
  AND ABS(EXTRACT(EPOCH FROM (v.timestamp - m.timestamp))) <= 30
WHERE v.vehicle_id = $1 
  AND v.timestamp >= NOW() - INTERVAL '24 hours'
```

**Efficiency Calculation:**
- **AC Consumed** (from meter): Energy billed by utility
- **DC Delivered** (from vehicle): Energy actually stored in battery
- **Efficiency = (DC/AC) Ã— 100%**: Typically 85-95% (conversion losses)
- **Alert Threshold**: <85% indicates hardware fault or energy leakage

## ğŸš€ Quick Start

### Prerequisites

- **Node.js** 20+ ([Download](https://nodejs.org/))
- **Docker** & **Docker Compose** ([Download](https://www.docker.com/))
- **Git** ([Download](https://git-scm.com/))

### Installation

```bash
# Clone repository
git clone <your-repo-url>
cd hseie

# Install dependencies
npm install

# Start PostgreSQL
docker-compose up -d postgres

# Wait for database to be ready (check health)
docker-compose logs -f postgres
# Wait until you see: "database system is ready to accept connections"

# Start API in development mode
npm run start:dev
```

### Verify Installation

```bash
# Check API health
curl http://localhost:3000/health

# Expected response:
# {
#   "status": "ok",
#   "timestamp": "2026-02-09T12:00:00.000Z",
#   "service": "High-Scale Energy Ingestion Engine",
#   "version": "1.0.0"
# }

# Open Swagger API documentation
open http://localhost:3000/api
```

## ğŸ“¡ API Endpoints

### Ingestion

**POST /v1/ingest/meter**
```bash
curl -X POST http://localhost:3000/v1/ingest/meter \
  -H "Content-Type: application/json" \
  -d '{
    "meterId": "METER_001",
    "kwhConsumedAc": 10.5,
    "voltage": 230,
    "timestamp": "2026-02-09T12:00:00Z"
  }'
```

**POST /v1/ingest/vehicle**
```bash
curl -X POST http://localhost:3000/v1/ingest/vehicle \
  -H "Content-Type: application/json" \
  -d '{
    "vehicleId": "VEHICLE_001",
    "soc": 75.5,
    "kwhDeliveredDc": 9.5,
    "batteryTemp": 28.5,
    "timestamp": "2026-02-09T12:00:00Z"
  }'
```

### Analytics

**GET /v1/analytics/performance/:vehicleId**
```bash
curl http://localhost:3000/v1/analytics/performance/VEHICLE_001

# Response:
# {
#   "vehicleId": "VEHICLE_001",
#   "period": "24h",
#   "totalEnergyConsumedAc": 120.50,
#   "totalEnergyDeliveredDc": 105.30,
#   "efficiencyRatio": 87.52,
#   "avgBatteryTemp": 28.75
# }
```

**GET /v1/analytics/stats**
```bash
curl http://localhost:3000/v1/analytics/stats
```

**GET /v1/ingest/vehicle/:vehicleId/current**
```bash
curl http://localhost:3000/v1/ingest/vehicle/VEHICLE_001/current
```

## ğŸ§ª Testing with IoT Simulator

The included IoT simulator generates realistic telemetry data.

### Start Simulator

```bash
# Simulate 100 devices (default)
npm run simulator

# Simulate 1000 devices
NUM_DEVICES=1000 npm run simulator

# Fast mode (1-second intervals instead of 60)
NUM_DEVICES=100 INTERVAL_MS=1000 npm run simulator
```

### Simulator Output

```
ğŸš€ ================================================
ğŸš€  IoT Device Simulator Started
ğŸš€ ================================================
ğŸ“¡  API Endpoint: http://localhost:3000/v1/ingest
ğŸ”¢  Number of Devices: 100
â±ï¸   Heartbeat Interval: 60000ms (60s)
ğŸ“Š  Expected Throughput: 3 writes/sec
ğŸš€ ================================================

âœ… API connection successful

âœ“ Device 1: SoC=65.23%, Efficiency=89.2%
âœ“ Device 2: SoC=72.45%, Efficiency=91.5%

ğŸ“Š Batch complete: 200 records sent in 1234ms (162 writes/sec)
```

## ğŸ³ Docker Deployment

### Start All Services

```bash
# Build and start API + PostgreSQL
docker-compose up -d --build

# View logs
docker-compose logs -f api

# Stop services
docker-compose down

# Stop and remove all data
docker-compose down -v
```

### Access Services

- API: http://localhost:3000
- Swagger Docs: http://localhost:3000/api
- PostgreSQL: localhost:5432

## ğŸ“ Project Structure

```
hseie/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.ts                  # Application entry point
â”‚   â”œâ”€â”€ app.module.ts            # Root module
â”‚   â”œâ”€â”€ health.controller.ts     # Health check
â”‚   â”‚
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â”œâ”€â”€ ingestion.module.ts
â”‚   â”‚   â”œâ”€â”€ ingestion.controller.ts
â”‚   â”‚   â”œâ”€â”€ ingestion.service.ts
â”‚   â”‚   â”œâ”€â”€ dto/
â”‚   â”‚   â”‚   â”œâ”€â”€ meter-telemetry.dto.ts
â”‚   â”‚   â”‚   â””â”€â”€ vehicle-telemetry.dto.ts
â”‚   â”‚   â””â”€â”€ entities/
â”‚   â”‚       â”œâ”€â”€ meter-current.entity.ts
â”‚   â”‚       â”œâ”€â”€ meter-history.entity.ts
â”‚   â”‚       â”œâ”€â”€ vehicle-current.entity.ts
â”‚   â”‚       â””â”€â”€ vehicle-history.entity.ts
â”‚   â”‚
â”‚   â””â”€â”€ analytics/
â”‚       â”œâ”€â”€ analytics.module.ts
â”‚       â”œâ”€â”€ analytics.controller.ts
â”‚       â”œâ”€â”€ analytics.service.ts
â”‚       â””â”€â”€ dto/
â”‚           â””â”€â”€ performance-response.dto.ts
â”‚
â”œâ”€â”€ database/
â”‚   â””â”€â”€ init.sql                 # Database schema & partitions
â”‚
â”œâ”€â”€ simulator/
â”‚   â”œâ”€â”€ iot-simulator.ts         # IoT device simulator
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ docker-compose.yml           # Docker orchestration
â”œâ”€â”€ Dockerfile                   # API container image
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â””â”€â”€ README.md
```

## ğŸ” Database Schema

### Hot Tables

```sql
-- Current state (UPSERT)
CREATE TABLE meter_current (
    meter_id VARCHAR(50) PRIMARY KEY,
    kwh_consumed_ac DECIMAL(10, 4),
    voltage DECIMAL(6, 2),
    timestamp TIMESTAMPTZ,
    updated_at TIMESTAMPTZ
);

CREATE TABLE vehicle_current (
    vehicle_id VARCHAR(50) PRIMARY KEY,
    soc DECIMAL(5, 2),
    kwh_delivered_dc DECIMAL(10, 4),
    battery_temp DECIMAL(5, 2),
    timestamp TIMESTAMPTZ,
    updated_at TIMESTAMPTZ
);
```

### Cold Tables (Partitioned)

```sql
-- Historical data (INSERT only)
CREATE TABLE meter_history (
    id BIGSERIAL,
    meter_id VARCHAR(50),
    kwh_consumed_ac DECIMAL(10, 4),
    voltage DECIMAL(6, 2),
    timestamp TIMESTAMPTZ,
    created_at TIMESTAMPTZ,
    PRIMARY KEY (id, timestamp)
) PARTITION BY RANGE (timestamp);

CREATE TABLE vehicle_history (
    id BIGSERIAL,
    vehicle_id VARCHAR(50),
    soc DECIMAL(5, 2),
    kwh_delivered_dc DECIMAL(10, 4),
    battery_temp DECIMAL(5, 2),
    timestamp TIMESTAMPTZ,
    created_at TIMESTAMPTZ,
    PRIMARY KEY (id, timestamp)
) PARTITION BY RANGE (timestamp);
```

## ğŸ“Š Performance Metrics

### Current Scale (10K Devices)

| Metric | Value |
|--------|-------|
| Devices | 20,000 (10K meters + 10K vehicles) |
| Writes/Second | 333 (average) |
| Records/Day | 28.8 million |
| Records/Year | 10.5 billion |
| Storage/Year | ~1 TB (raw data) |
| Query Time (24h) | <500ms |
| Dashboard Query | <10ms |

### Optimization Techniques

1. **Partition Pruning**: Reduces scan from 10B rows â†’ 58M rows (174Ã— reduction)
2. **Composite Indexes**: `(vehicle_id, timestamp DESC)` enables index-only scans
3. **UPSERT Strategy**: Hot tables use `INSERT ON CONFLICT UPDATE` for atomic updates
4. **Connection Pooling**: 20 connections to handle concurrent requests
5. **Fillfactor 70**: Leaves room for UPDATEs to avoid page splits

## ğŸ“ Key Concepts

### INSERT vs UPSERT

**INSERT (Cold Tables)**
- Always creates a new row
- Perfect for audit trails
- Never overwrites data

**UPSERT (Hot Tables)**
- Updates if row exists, inserts if not
- Perfect for "current state"
- Prevents duplicates

### Hot vs Cold Storage

**Hot Storage**
- Small, fast, frequently accessed
- Random reads (dashboard queries)
- Example: "What's current battery %?"

**Cold Storage**
- Large, slower, infrequently accessed
- Sequential scans (analytics)
- Example: "Show efficiency trend last 30 days"

## ğŸš€ Scaling Guide

### To 100K Devices (3,333 writes/sec)

```bash
# Add more API instances
docker-compose up -d --scale api=10

# Add Nginx load balancer (see docker-compose.yml)
```

### To 500K+ Devices

- Add message queue (Redis + Bull)
- Add database read replicas
- Implement batch processing
- Add caching layer (Redis)

## ğŸ› ï¸ Development

```bash
# Install dependencies
npm install

# Run in development mode (with hot reload)
npm run start:dev

# Build for production
npm run build

# Run production build
npm run start:prod
```

## ğŸ“ Environment Variables

Create a `.env` file in the root directory:

```env
NODE_ENV=development
PORT=3000

# Database
DB_HOST=localhost
DB_PORT=5432
DB_USERNAME=postgres
DB_PASSWORD=postgres
DB_DATABASE=energy_ingestion
```

## ğŸ”§ Troubleshooting

### Database Connection Failed

```bash
# Check if PostgreSQL is running
docker-compose ps

# Restart PostgreSQL
docker-compose restart postgres

# Check logs
docker-compose logs postgres
```

### Port Already in Use

```bash
# Check what's using port 3000
lsof -i :3000  # macOS/Linux
netstat -ano | findstr :3000  # Windows

# Kill the process or change PORT in .env
```

### Simulator Can't Connect

```bash
# Make sure API is running
curl http://localhost:3000/health

# Check API logs
docker-compose logs -f api
```

## ğŸ“š API Documentation

Full API documentation is available via Swagger UI:

**http://localhost:3000/api**

## ğŸ¤ Contributing

This is a technical assessment project. For questions or improvements, please contact the author.

## ğŸ“„ License

MIT License - See LICENSE file for details

## ğŸ‘¨â€ğŸ’» Author

**Devendra Maharshi**

## ğŸ¯ Assignment Deliverables Checklist

âœ… **Source Code**: Complete NestJS application with TypeScript  
âœ… **Docker Compose**: Spins up API + PostgreSQL  
âœ… **Database Schema**: Hot/Cold separation with partitioning  
âœ… **Polymorphic Ingestion**: Separate endpoints for meter and vehicle  
âœ… **UPSERT Logic**: Hot tables use atomic operations  
âœ… **INSERT Logic**: Cold tables append-only  
âœ… **Analytics Endpoint**: `/v1/analytics/performance/:vehicleId`  
âœ… **No Full Table Scan**: Partition pruning + composite indexes  
âœ… **README**: Architecture explanation and scaling strategy  
âœ… **IoT Simulator**: Realistic test data generation  

## ğŸš€ Next Steps

1. Run the application: `npm install && docker-compose up -d`
2. Start the simulator: `npm run simulator`
3. View API docs: http://localhost:3000/api
4. Query analytics: `curl http://localhost:3000/v1/analytics/performance/VEHICLE_001`

---

**Built with â¤ï¸ for high-scale IoT data processing**

